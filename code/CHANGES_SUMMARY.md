# è¯„åˆ†ç³»ç»Ÿå®æ–½ - æ”¹åŠ¨æ€»ç»“

## ğŸ“¦ æ–°å¢æ–‡ä»¶ (3ä¸ª)

### 1. `client/src/hooks/useGestureScore.ts`
**ä½œç”¨ï¼š** è¯„åˆ†ç»Ÿè®¡ Hook  
**åŠŸèƒ½ï¼š**
- ä» WebSocket æ¶ˆæ¯æå–ç½®ä¿¡åº¦å’ŒåŒ¹é…ç»“æœ
- ç»´æŠ¤å®æ—¶åˆ†æ•°ï¼ˆ0-100ï¼‰
- ç»Ÿè®¡æ€»å¸§æ•°ã€æ­£ç¡®å¸§æ•°ã€å‡†ç¡®ç‡
- æ— æ‰‹å¸§è‡ªåŠ¨æ’é™¤

**æ ¸å¿ƒé€»è¾‘ï¼š**
```typescript
const onMessage = useCallback((msg: GestureMessage) => {
  if (!msg?.ok || msg.data?.type !== "gesture_result") return;
  const { hands_detected, confidence, target, predicted } = msg.data;
  
  if (!hands_detected) return; // æ— æ‰‹ä¸è®¡å…¥
  
  const currentScore = Math.round(confidence * 100);
  setScore(currentScore);
  setTotal(t => t + 1);
  
  if (predicted === target) setHits(h => h + 1);
}, []);
```

---

### 2. `client/src/components/WebcamOverlay.tsx`
**ä½œç”¨ï¼š** å®æ—¶è¯„åˆ†å åŠ å±‚  
**åŠŸèƒ½ï¼š**
- å³ä¸Šè§’ Badge æ˜¾ç¤º Live Score
- åº•éƒ¨è¿›åº¦æ¡åæ˜ åˆ†æ•°
- æ ¹æ®åˆ†æ•°åŠ¨æ€è°ƒæ•´é¢œè‰²ï¼ˆç»¿/æ©™/é»„/çº¢ï¼‰

**é¢œè‰²æ˜ å°„ï¼š**
- 90+: ç»¿è‰² (ä¼˜ç§€)
- 75-89: æ©™è‰² (è‰¯å¥½)
- 60-74: é»„è‰² (åˆæ ¼)
- <60: çº¢è‰² (éœ€è¦æ”¹è¿›)

---

### 3. `è¯„åˆ†ç³»ç»Ÿå®æ–½è¯´æ˜.md`
**ä½œç”¨ï¼š** å®Œæ•´çš„å®æ–½æ–‡æ¡£  
**å†…å®¹ï¼š**
- æ”¹åŠ¨è¯¦æƒ…
- å¯åŠ¨éªŒè¯æ­¥éª¤
- è‡ªæµ‹æ¸…å•
- å‚æ•°è°ƒæ•´æŒ‡å—
- æ•…éšœæ’é™¤

---

## ğŸ”§ ä¿®æ”¹æ–‡ä»¶ (4ä¸ª)

### 1. `server/ml/realtime_recognition.py`

#### æ”¹åŠ¨ 1ï¼šå¯¼å…¥å’Œé…ç½®
```python
from collections import defaultdict

# EMA å¹³æ»‘é…ç½®
ema_conf = defaultdict(float)
EMA_ALPHA = 0.35
```

#### æ”¹åŠ¨ 2ï¼šæ–°å¢ EMA å¹³æ»‘å‡½æ•°
```python
def ema_smooth(key, value):
    """æŒ‡æ•°ç§»åŠ¨å¹³å‡å¹³æ»‘"""
    prev = ema_conf[key]
    smoothed = EMA_ALPHA * value + (1 - EMA_ALPHA) * prev
    ema_conf[key] = smoothed
    return smoothed
```

#### æ”¹åŠ¨ 3ï¼šæ–°å¢å…³é”®ç‚¹è´¨é‡æ£€æµ‹
```python
def check_landmarks_quality(hand_landmarks):
    """æ£€æµ‹å…³é”®ç‚¹è´¨é‡"""
    for lm in hand_landmarks.landmark:
        if lm.x < 0 or lm.x > 1 or lm.y < 0 or lm.y > 1:
            return False
        if hasattr(lm, 'visibility') and lm.visibility < 0.5:
            return False
    return True
```

#### æ”¹åŠ¨ 4ï¼šé‡å†™ process_frame å‡½æ•°
**åŸé€»è¾‘ï¼š** è¿”å›æ—§æ ¼å¼ï¼ˆgestures æ•°ç»„ï¼‰  
**æ–°é€»è¾‘ï¼š**
- æ¥æ”¶ `target_gesture` å‚æ•°
- è¿”å›æ–°åè®® `{ok, data: {hands_detected, target, predicted, confidence, landmarks_ok}}`
- åº”ç”¨è´¨é‡é™æƒï¼ˆ0.5xï¼‰å’Œé”™è¯¯é™æƒï¼ˆ0.6xï¼‰
- åº”ç”¨ EMA å¹³æ»‘

**æ ¸å¿ƒä»£ç ï¼š**
```python
# è´¨é‡é—¸é—¨
if not landmarks_ok:
    raw_confidence *= 0.5

# é”™è¯¯é™æƒ
if target_gesture and predicted_label != target_gesture:
    raw_confidence *= 0.6

# EMA å¹³æ»‘
confidence_smooth = ema_smooth(target_gesture or predicted_label, raw_confidence)

return {
    'ok': True,
    'data': {
        'type': 'gesture_result',
        'hands_detected': True,
        'target': target_gesture,
        'predicted': predicted_label,
        'confidence': float(confidence_smooth),
        'landmarks_ok': landmarks_ok
    }
}
```

#### æ”¹åŠ¨ 5ï¼šä¸»å¾ªç¯æ”¯æŒ target_gesture
```python
if message.get('type') == 'process_frame':
    frame_data = message.get('frame') or message.get('frame_data')
    target_gesture = message.get('target_gesture', '')  # æ–°å¢
    
    if frame_data:
        result = process_frame(frame_data, target_gesture)
        print(json.dumps(result), flush=True)
```

---

### 2. `client/src/components/WebcamViewer.tsx`

#### æ”¹åŠ¨ 1ï¼šå¯¼å…¥æ–° Hook å’Œç»„ä»¶
```typescript
import { useGestureScore } from '@/hooks/useGestureScore';
import { WebcamOverlay } from '@/components/WebcamOverlay';
```

#### æ”¹åŠ¨ 2ï¼šä½¿ç”¨è¯„åˆ† Hook
```typescript
const { score, accuracy, total, hits, onMessage: onScoreMessage, reset: resetScore } = useGestureScore();
```

#### æ”¹åŠ¨ 3ï¼šå¤„ç† WebSocket æ¶ˆæ¯
```typescript
const handleWebSocketMessage = (data: any) => {
  // æ–°åè®®ï¼šå¤„ç†è¯„åˆ†æ¶ˆæ¯
  if (data.ok !== undefined) {
    onScoreMessage(data);
  }
  
  // æ—§åè®®å…¼å®¹...
};
```

#### æ”¹åŠ¨ 4ï¼šå¼€å§‹è¯†åˆ«æ—¶é‡ç½®è¯„åˆ†
```typescript
const startGestureRecognition = async (gesture: string) => {
  // ... ç°æœ‰ä»£ç  ...
  resetScore(); // æ–°å¢
  // ... ç°æœ‰ä»£ç  ...
};
```

#### æ”¹åŠ¨ 5ï¼šæ·»åŠ  Overlay åˆ°è§†é¢‘å®¹å™¨
```typescript
<div className="relative aspect-video bg-muted rounded-lg overflow-hidden">
  <video ref={videoRef} ... />
  <canvas ref={canvasRef} className="hidden" />
  
  {/* æ–°å¢ï¼šè¯„åˆ† Overlay */}
  {isRecognizing && <WebcamOverlay score={score} />}
  
  {/* ... å…¶ä»–å…ƒç´  ... */}
</div>
```

#### æ”¹åŠ¨ 6ï¼šæ›´æ–°ç»Ÿè®¡é¢æ¿
```typescript
<div className="space-y-2">
  <h3 className="font-medium text-sm">{lang.stats.title}</h3>
  <div className="text-xs text-muted-foreground">
    <div>{lang.stats.totalFrames}: {total}</div>
    <div>{lang.stats.correctFrames}: {hits}</div>
    <div>{lang.stats.accuracy}: {accuracy}%</div>
  </div>
</div>
```

---

### 3. `client/src/i18n/en.ts`

#### æ”¹åŠ¨ï¼šæ·»åŠ æ–°æ–‡æ¡ˆ
```typescript
stats: {
  title: "Recognition Stats",
  totalFrames: "Total Frames",
  correctFrames: "Correct Frames",  // æ–°å¢
  accuracy: "Accuracy",
  confidence: "Confidence",
  feedback: "Feedback",
  liveScore: "Live Score",           // æ–°å¢
},
```

---

### 4. `server/websocket_service.ts`

**æ— éœ€æ”¹åŠ¨** - å·²ç»æ­£ç¡®ä¼ é€’ `target_gesture` å‚æ•°åˆ° Pythonï¼ˆç¬¬ 243 è¡Œï¼‰ã€‚

---

## ğŸ“Š æ•°æ®æµå›¾

```
ç”¨æˆ·æ‘„åƒå¤´
    â†“
WebcamViewer (å‰ç«¯)
    â†“ [æ¯å¸§å‘é€ base64 å›¾åƒ + target_gesture]
WebSocket æœåŠ¡ (Node.js)
    â†“ [è½¬å‘åˆ° Python]
realtime_recognition.py (åç«¯)
    â†“
1. MediaPipe æ£€æµ‹æ‰‹éƒ¨
2. æå–å…³é”®ç‚¹
3. KNN æ¨¡å‹é¢„æµ‹æ‰‹åŠ¿
4. æ£€æŸ¥å…³é”®ç‚¹è´¨é‡
5. è®¡ç®—åŸå§‹ç½®ä¿¡åº¦
6. åº”ç”¨è´¨é‡é™æƒ (0.5x if bad)
7. åº”ç”¨é”™è¯¯é™æƒ (0.6x if mismatch)
8. åº”ç”¨ EMA å¹³æ»‘ (alpha=0.35)
    â†“ [è¿”å› JSON åè®®]
WebSocket æœåŠ¡
    â†“ [è½¬å‘åˆ°å‰ç«¯]
useGestureScore Hook
    â†“
1. æå– confidence (0-1)
2. è½¬æ¢ä¸º score (0-100)
3. åˆ¤æ–­æ˜¯å¦å‘½ä¸­ (predicted === target)
4. æ›´æ–°ç»Ÿè®¡ (total, hits, accuracy)
    â†“
WebcamOverlay ç»„ä»¶
    â†“
æ˜¾ç¤ºå®æ—¶è¯„åˆ†ï¼ˆBadge + è¿›åº¦æ¡ï¼‰
```

---

## ğŸ¯ æ ¸å¿ƒç®—æ³•

### EMA å¹³æ»‘å…¬å¼
```
conf_smooth = alpha * conf_current + (1 - alpha) * conf_previous
```
- `alpha = 0.35`ï¼šå½“å‰å¸§æƒé‡
- `1 - alpha = 0.65`ï¼šå†å²æƒé‡
- æ•ˆæœï¼šå¹³æ»‘æŠ–åŠ¨ï¼Œå“åº”é€‚ä¸­

### ç½®ä¿¡åº¦è®¡ç®—æµç¨‹
```python
# 1. æ¨¡å‹åŸå§‹è¾“å‡º
raw_conf = max(model.predict_proba(features)[0])

# 2. è´¨é‡é™æƒ
if not landmarks_ok:
    raw_conf *= 0.5

# 3. é”™è¯¯é™æƒ
if predicted != target:
    raw_conf *= 0.6

# 4. EMA å¹³æ»‘
conf_smooth = ema_smooth(target, raw_conf)
```

### å‡†ç¡®ç‡è®¡ç®—
```typescript
accuracy = (hits / total) * 100
```
- `hits`ï¼špredicted === target çš„å¸§æ•°
- `total`ï¼šæœ‰æ‰‹çš„æ€»å¸§æ•°ï¼ˆæ— æ‰‹å¸§ä¸è®¡å…¥ï¼‰

---

## ğŸ§ª æµ‹è¯•åœºæ™¯è¦†ç›–

| åœºæ™¯ | é¢„æœŸè¡Œä¸º | éªŒè¯ç‚¹ |
|------|----------|--------|
| æ­£ç¡®æ‰‹åŠ¿ 1-2 ç§’ | Score â‰¥75ï¼Œç»¿è‰²/æ©™è‰² | Accuracy ä¸Šå‡ |
| é”™è¯¯æ‰‹åŠ¿ | Score <60ï¼Œçº¢è‰²/é»„è‰² | Accuracy ä¸‹é™/ä¸å˜ |
| æ— æ‰‹ | ç»Ÿè®¡ä¸å˜ | Total Frames ä¸å¢åŠ  |
| æš—å…‰/èƒŒå…‰ | Score ç•¥é™ä½†å¹³æ»‘ | æ— å‰§çƒˆæŠ–åŠ¨ |
| WebSocket æ–­å¼€ | è‡ªåŠ¨é‡è¿ | åˆ·æ–°é¡µé¢åæ¢å¤ |

---

## ğŸ” å‘åå…¼å®¹æ€§

1. **æ—§åè®®æ”¯æŒï¼š** `handleWebSocketMessage()` ä»å¤„ç† `data.type === 'gesture_result'` çš„æ—§æ¶ˆæ¯
2. **Python æ¨¡å‹æœªåŠ è½½ï¼š** è‡ªåŠ¨é™çº§åˆ°æ¨¡æ‹Ÿæ•°æ®ï¼ˆ`predicted='A', confidence=0.75`ï¼‰
3. **WebSocket æœåŠ¡ï¼š** å·²æœ‰çš„ `target_gesture` ä¼ é€’é€»è¾‘æ— éœ€æ”¹åŠ¨

---

## ğŸ“ å‚æ•°è°ƒä¼˜å»ºè®®

| å‚æ•° | ä½ç½® | é»˜è®¤å€¼ | å»ºè®®èŒƒå›´ | æ•ˆæœ |
|------|------|--------|----------|------|
| EMA_ALPHA | `realtime_recognition.py:51` | 0.35 | 0.2 - 0.5 | è¶Šé«˜è¶Šçµæ• |
| è´¨é‡é™æƒç³»æ•° | `realtime_recognition.py:170` | 0.5 | 0.3 - 0.7 | è¶Šä½è¶Šä¸¥æ ¼ |
| é”™è¯¯é™æƒç³»æ•° | `realtime_recognition.py:174` | 0.6 | 0.3 - 0.8 | è¶Šä½è¶Šä¸¥æ ¼ |
| é¢œè‰²é˜ˆå€¼ï¼ˆç»¿ï¼‰ | `WebcamOverlay.tsx:19` | 90 | 85 - 95 | ä¼˜ç§€æ ‡å‡† |
| é¢œè‰²é˜ˆå€¼ï¼ˆæ©™ï¼‰ | `WebcamOverlay.tsx:20` | 75 | 70 - 80 | è‰¯å¥½æ ‡å‡† |
| é¢œè‰²é˜ˆå€¼ï¼ˆé»„ï¼‰ | `WebcamOverlay.tsx:21` | 60 | 55 - 65 | åˆæ ¼æ ‡å‡† |

---

## ğŸ› å·²çŸ¥é™åˆ¶

1. **å¤šæ‰‹æ£€æµ‹ï¼š** ç›®å‰ä»…å¤„ç†ç¬¬ä¸€ä¸ªæ£€æµ‹åˆ°çš„æ‰‹ï¼ˆ`results.multi_hand_landmarks[0]`ï¼‰
2. **æ¨¡å‹ä¾èµ–ï¼š** éœ€è¦ `asl_knn_model.pkl` æ–‡ä»¶å­˜åœ¨ï¼Œå¦åˆ™é™çº§åˆ°æ¨¡æ‹Ÿæ•°æ®
3. **å®æ—¶æ€§ï¼š** å¸§ç‡å–å†³äº `requestAnimationFrame` å’Œ Python å¤„ç†é€Ÿåº¦
4. **æ— æ‰‹åˆ¤æ–­ï¼š** MediaPipe æ£€æµ‹å¤±è´¥æ—¶ç«‹å³è¿”å› `hands_detected=false`ï¼Œä¸åŒºåˆ†"æš‚æ—¶é®æŒ¡"å’Œ"çœŸæ­£æ— æ‰‹"

---

## âœ… æ£€æŸ¥æ¸…å•

### åç«¯
- [x] Python ä¾èµ–å·²å®‰è£…ï¼ˆmediapipe, opencv, numpy, joblib, scikit-learnï¼‰
- [x] `realtime_recognition.py` å¯¼å…¥ `defaultdict`
- [x] EMA å‡½æ•°å®ç°æ­£ç¡®
- [x] è´¨é‡æ£€æµ‹å‡½æ•°å®ç°
- [x] `process_frame()` æ¥å— `target_gesture` å‚æ•°
- [x] è¿”å›æ–° JSON åè®®
- [x] ä¸»å¾ªç¯ä¼ é€’ `target_gesture`

### å‰ç«¯
- [x] `useGestureScore.ts` åˆ›å»º
- [x] `WebcamOverlay.tsx` åˆ›å»º
- [x] `WebcamViewer.tsx` å¯¼å…¥æ–° Hook å’Œç»„ä»¶
- [x] WebSocket æ¶ˆæ¯å¤„ç†è°ƒç”¨ `onScoreMessage()`
- [x] è§†é¢‘å®¹å™¨æ·»åŠ  Overlay
- [x] ç»Ÿè®¡é¢æ¿æ›´æ–°ä¸ºæ–°å­—æ®µ
- [x] i18n æ–‡æ¡ˆæ·»åŠ  `correctFrames` å’Œ `liveScore`
- [x] æ—  linter é”™è¯¯

### æ–‡æ¡£
- [x] `è¯„åˆ†ç³»ç»Ÿå®æ–½è¯´æ˜.md` åˆ›å»º
- [x] `CHANGES_SUMMARY.md` åˆ›å»º
- [x] `å¿«é€ŸéªŒè¯-è¯„åˆ†ç³»ç»Ÿ.bat` åˆ›å»º

---

## ğŸš€ æäº¤ä¿¡æ¯

```
feat(scoring): live score overlay and accuracy stats for gesture recognition

- Backend: Add EMA smoothing (alpha=0.35) for confidence calculation
- Backend: Implement landmarks quality check with 0.5x penalty
- Backend: Return new JSON protocol with hands_detected, predicted, target, confidence, landmarks_ok
- Frontend: Add useGestureScore hook for score/total/hits/accuracy tracking
- Frontend: Add WebcamOverlay component with live score badge and progress bar
- Frontend: Integrate overlay into WebcamViewer with color-coded feedback
- Frontend: Add Total Frames, Correct Frames, Accuracy stats to Recognition Stats panel
- i18n: Add correctFrames and liveScore English labels

No hands frames are excluded from statistics.
Color zones: green (90+), orange (75-89), yellow (60-74), red (<60).
```

---

## ğŸ“… å®æ–½æ—¥æœŸ
2025-10-16

## ğŸ‘¨â€ğŸ’» å®æ–½è€…
AI Assistant (Claude Sonnet 4.5)

---

**çŠ¶æ€ï¼šâœ… å·²å®Œæˆå¹¶é€šè¿‡ linter æ£€æŸ¥**




